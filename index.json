[{"content":"1. Towards audio language modeling - an overview 缘起压缩传数据，后来这种离散化连续语音音频很适用于语音语言模型。\nSoundStream为万恶之源。\nⅠ. SoundStream (1) 模型 编码器——将raw audio映射到嵌入序列 量化器——用一组有限码本的矢量和代替每个嵌入 解码器——从量化嵌入产生有损的重建\n所有卷积均为因果卷积 训练和离线推理只对过去padding，流式推理不使用padding 膨胀卷积（扩张卷积，空洞卷积）含于每个残差块，间隔采样 跨步卷积 每次下采样channel都乘2，最后的Conv1D将维度限制为D 使用ELU激活函数，不进行任何的归一化 FiLM(feature-wise Linear Modulation) conditioning，一种调节机制。\n量化器的输出用bps表达。采样率为24000的话，经过编码器的处理后被压缩为1/320——75，相当于每秒75个采样点。那么如果针对于6000bps而言，6000 bps / 75 HZ = 80 bit。那么需要存2^80个矢量的码本，太大太不可行。 多个量化器进行残差分摊，分摊针对的是bit，那么每个量化器只需要2^(80/8)=1024个矢量的码本。 量化算法来源于VQ-VAE-2，额外用到k-means进行初始化，码本向量每用到随机替换。\n(2) 训练 两种判别器\nⅡ. EnCodec Ⅲ. AudioDec Ⅳ. AcademicCodec Ⅴ. SoundStorm Ⅵ. DAC Ⅶ. SpeechTokenizer Ⅷ. FuncCodec A. AudioLM B. AudioGen C. VALL-E D. MusicLM E. VALL-E X F. VioLA G. MusicGen H. AudioPaLM I. SpeechX J. LauraGPT K. UniAudioS 2. Sparks of Large Audio Models: A Survey and Outlook ","permalink":"https://ajkpix.github.io/posts/read/read2/","summary":"\u003ch2 id=\"1-towards-audio-language-modeling---an-overview\"\u003e1. Towards audio language modeling - an overview\u003c/h2\u003e\n\u003cp\u003e缘起压缩传数据，后来这种离散化连续语音音频很适用于语音语言模型。\u003c/p\u003e\n\u003cp\u003eSoundStream为万恶之源。\u003c/p\u003e\n\u003ch3 id=\"-soundstream\"\u003eⅠ. SoundStream\u003c/h3\u003e\n\u003ch4 id=\"1-模型\"\u003e(1) 模型\u003c/h4\u003e\n\u003cp\u003e编码器——将raw audio映射到嵌入序列\u003cbr/\u003e\n量化器——用一组有限码本的矢量和代替每个嵌入\u003cbr/\u003e\n解码器——从量化嵌入产生有损的重建\u003cbr/\u003e\u003c/p\u003e","title":"两则综述"},{"content":"0. 摘要 专门设计的、结合两方面的新模型。新的评估测试集SLMTokBench benchmark。\n1. 引言 LLM的卓越表现促进了语音语言模型的发展。在多种语音处理任务中都使用到了离散语音表示。如下图所示。\n语义表征(semantic tokens)通常是自监督的预训练模型，训练目标是掩码语言建模，通过特定中间层对表征进行k-means聚类，表征是一维结构的序列。声学表征(acoustic tokens)通常是神经音频编解码器模型，训练目标是音频重构，通过RVQ(residual vector quantization)进行离散化，表征是由时间步长和量化器两个维度组成的矩阵。\n基于这两种离散语音表征，语音语言模型的建模方法有三种：\n语义表征+外部单元声码器。质量低、声学细节丢失。 以VALL-E这种zero-shot TTS为例的声学表征模型。声学表征中的信息太复杂导致的语音内容不准确。 级联语义表征模型和声学表征模型。级联模型的缺点，以及信息冗余重复、浪费。这三者的表现与作者的模型相比如下表所示。 Accurate Content High-quality Speech Single Tokenizer Semantic LM yes no yes Acoustic LM no yes yes Hierarchical LM yes yes no USLM(thers) no yes yes 因此作者认为理想的语音表征应该保有两个关键特性：\n与文本强对齐。 语音信息的有效保存(损失少)。 因此提出了Speech Language Model Token Benchmark测试集来评估语音表征是否适用于语音语言模型。评估表明语义表征高对齐、低信息，声学表征高信息、低对齐。作者的做法是基于声学表征模型，在RVQ结构中进行信息解耦，通过语义教师指导使得第一个RVQ quantizer生成包含文本信息的表征，后续的quantizer对信息进行补充。\n实验结果表明，USLM在语音重建性能无影响的前提下，在语音处理任务上更强。\n论文贡献为三点:\nSpeechTokenizer，基于Acoustic Tokens保有Semantic Tokens。 SLMTokBench benchmark，适用于评估在语音语言模型上的表现。 USLM，outperforms VALL-E on zero-shot TTS task。 2. 结论 依旧是三点贡献。\n3. 测试集SLMTokBench 根据两个特性来评测模型效果。\n4. SpeechTolenizer 基于LSTM-\u0026gt;BiLSTM的EnCodec，HuBert作为语义教师指导残差量化过程。余弦相似度与伪标签，获得损失。训练任务是重构任务与语义蒸馏任务。在重构任务中和EnCodec一样使用了GAN网络\n","permalink":"https://ajkpix.github.io/posts/read/read1/","summary":"\u003ch2 id=\"0-摘要\"\u003e0. 摘要\u003c/h2\u003e\n\u003cp\u003e专门设计的、结合两方面的新模型。新的评估测试集SLMTokBench benchmark。\u003c/p\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eLLM的卓越表现促进了语音语言模型的发展。在多种语音处理任务中都使用到了离散语音表示。如下图所示。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"../read1/%e7%a6%bb%e6%95%a3%e8%af%ad%e9%9f%b3%e8%a1%a8%e5%be%81.png\" alt=\"离散语音表征\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e语义表征(semantic tokens)通常是自监督的预训练模型，训练目标是掩码语言建模，通过特定中间层对表征进行k-means聚类，表征是一维结构的序列。声学表征(acoustic tokens)通常是神经音频编解码器模型，训练目标是音频重构，通过RVQ(residual vector quantization)进行离散化，表征是由时间步长和量化器两个维度组成的矩阵。\u003c/p\u003e","title":"SpeechTokenizer: Unified Speech Tokenizer For Speech Language Models"},{"content":"一. EnCodec 1. 模型任务 EnCodec是在SoundStream模型的基础上提出的，用于实现音频数据的高效压缩。其被提出是为了解决音频数据的实时传输，因为要保证数据传输的实时性，所以需要对音频数据进行压缩，同时也要保证被压缩的质量。该工作就是利用神经网络来解决压缩与恢复工作。\n2. 模型发展 压缩可以追溯到AE(Auto Encoder)模型，是一个编解码模型，由编码器进行压缩，解码器进行恢复。这是一个自监督模型，它只需要对模型的输入x和模型的输出x`进行损失计算即可。\n然而由于AE模型编码器编码出来的向量空间不规整，其无法适用于生成任务，因为解码器并不能识别一个随意的向量。因为为了使编码空间规整，VAE(Variational Auto Encoder)模型被提出。其使编码向量满足正态分布，这样编码器也可以识别正态分布的向量了，进而实现随机生成任务。\n但是实验结果表明VAE模型的生成并不理想，进而被认为连续的编码向量不如转换为离散。这种类似选项或者是词汇的输入更符合人类创作的过程。VQ-VAE(Vector Quantised - Variational Auto Encoder)模型使用类似嵌入层(Embedding)的操作让解码器能够识别离散化的向量，该层被称作嵌入空间(embedding space)，在后续文章中被称作码本(codebook)。然而这个离散向量的空间又变成不好采样的了，为了解决这个问题作者训练了一个生成模型学习生成离散样本，进而解决上述问题。使用logit获取离散向量再把它映射成连续向量被认为是很多余的操作，在VQ-VAE模型中使用编码器的输出向量找寻码本中距离最近的向量进行替换，生成离散向量便是如此过程。那么问题又来了，反向传播怎么办？VQ-VAE基于“straight-through”技术使用了sg(stop gradient)运算解决了这个问题，细节不进行研究了。后续该运算也解决了码本训练的问题。\n3. 模型结构 模型框架图如下所示，主要由Encoder、Quantizer、Decoder以及Discriminator四部分构成，共计算了6处损失函数。\n编码器和解码器的设计基本是镜像的，由1D卷积层、B个卷积块、两层LSTM和最后一个1D卷积层组成。模型支持流式与非流式，只是padding和归一化不同。\n量化器是由RVQ(Residual Vector Quantization，残差向量量化)实现的，那么它与VQ-VAE中的VQ有何不同呢？单个码本经原作者计算是远远不够的，这样的话需要多个码本来解决问题，多个quantization block对应多个码本，之间用残差连接，相当于后面的quantization block量化的是前一个的误差，具体细节可在参考文献中了解。该部分还加入了一个较小的语言模型，根据当前时刻的RVQ向量来预测下一个时刻的RVQ向量，从而提前完成语音解码的工作。其加速了解码速度。\n模型使用多个判别器来评估解码器恢复的效果，这里用到了GAN模型。\n4. 参考文献 知乎：https://zhuanlan.zhihu.com/p/633744455\n知乎：https://zhuanlan.zhihu.com/p/672684663\n论文链接：https://arxiv.org/pdf/2210.13438\n二. VALL-E 1. 模型任务：语音合成大模型 上篇作者认为连续的音频数据经过Encodec压缩后变成了离散的数据，那就可以将这些离散的ID视作一个个token，用大量的语音数据训练出一个语音的“大语言模型”。微软推出的VALL-E和VALL-E-X模型做的就是这样的工作。zero-shot TTS!!!\n2. 模型过程 EnCodec由于将语音进行了压缩，重建质量高和压缩程度大，很好地解决了语音和文本在信息密度和长度上的巨大差异。并且Encodec有现成的解码器能够将离散表征转换为声音波形，无需训练额外的声码器。\nRQV中生成的离散向量被称为声学词元(acoustic tokens)，与被音素转换模块由文本提示词转换成的因素一同送入模型，预测后续的声学词元，进而被解码器转化为声学波形。\n知乎作者给出的结论：VALLE就是使用Encodec的离散表征来做acoustic tokens，堆大数据来做语音领域的大语言模型。\n3. 参考文献 知乎：https://zhuanlan.zhihu.com/p/672852107\n论文链接：https://arxiv.org/pdf/2301.02111\ndemo：https://lifeiteng.github.io/valle/index.html\n","permalink":"https://ajkpix.github.io/posts/blog/blog1/","summary":"\u003ch2 id=\"一-encodec\"\u003e一. EnCodec\u003c/h2\u003e\n\u003ch3 id=\"1-模型任务\"\u003e1. 模型任务\u003c/h3\u003e\n\u003cp\u003eEnCodec是在SoundStream模型的基础上提出的，用于实现音频数据的高效压缩。其被提出是为了解决音频数据的实时传输，因为要保证数据传输的实时性，所以需要对音频数据进行压缩，同时也要保证被压缩的质量。该工作就是利用神经网络来解决压缩与恢复工作。\u003c/p\u003e","title":"EnCodec在大语言模型上的调研"},{"content":"1. 修改 需要进行更改的文件为layouts/partials/post_meta.html、layouts/partials/author.html、layouts/partials/extend_head.html以及params。\nlayouts/partials/post_meta.html的更改链接为https://github.com/xyming108/sulv-hugo-papermod/blob/main/layouts/partials/post_meta.html，其更改结果如下：\n\u0026lt;!--如果单独复制这段代码，需要从 extend_head.html 中找到 font-awesome 引入，如下--\u0026gt; \u0026lt;!--\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css\u0026#34;\u0026gt;--\u0026gt; \u0026lt;style\u0026gt; i[id*=\u0026#34;post_meta_style\u0026#34;] { display: flex; align-items: center; margin: 0 0 10px 0; } .parent-post-meta { display: flex; flex-wrap: wrap; opacity: 0.8; } \u0026lt;/style\u0026gt; \u0026lt;span class=\u0026#34;parent-post-meta\u0026#34;\u0026gt; \u0026lt;span id=\u0026#34;post_meta_style_1\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;fa fa-calendar-check-o\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; {{- (.Date.Format (default \u0026#34;January 2, 2006\u0026#34; .Site.Params.DateFormat)) }} \u0026amp;nbsp;\u0026amp;nbsp; \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;!-- \u0026lt;span id=\u0026#34;post_meta_style_2\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;span class=\u0026#34;fa fa-calendar-plus-o\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;span\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;nbsp;更新\u0026amp;nbsp;{{- (.Lastmod.Format (.Site.Params.dateFormat | default \u0026#34;2006-01-02\u0026#34;)) }}--\u0026gt; \u0026lt;!-- \u0026amp;nbsp;|\u0026amp;nbsp;--\u0026gt; \u0026lt;!-- \u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/span\u0026gt;--\u0026gt; \u0026lt;span id=\u0026#34;post_meta_style_3\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;fa fa-file-word-o\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; {{- .WordCount }}字 \u0026amp;nbsp;\u0026amp;nbsp; \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;post_meta_style_4\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;fa fa-clock-o\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; {{- .ReadingTime }}分钟 \u0026amp;nbsp;\u0026amp;nbsp; \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;post_meta_style_5\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;fa fa-user-o\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; {{- with (partial \u0026#34;author.html\u0026#34; .) }} {{- . }} {{- end }} \u0026amp;nbsp;\u0026amp;nbsp; \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;post_meta_style_6\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;fa fa-tags\u0026#34; style=\u0026#34;opacity: 0.8\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span\u0026gt; {{- if .Params.tags }} \u0026lt;span class=\u0026#34;post-tags-meta\u0026#34;\u0026gt; {{- range $index, $value := ($.GetTerms \u0026#34;tags\u0026#34;) }} {{- if eq $index 0}} \u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34; style=\u0026#34;color: var(--secondary)!important;\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt; {{- else }} \u0026amp;nbsp;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34; style=\u0026#34;color: var(--secondary)!important;\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt; {{- end }} {{- end }} \u0026lt;/span\u0026gt; {{- end }} \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; 2. 理解 摸鱼ing\n","permalink":"https://ajkpix.github.io/posts/tech/tech/","summary":"\u003ch2 id=\"1-修改\"\u003e1. 修改\u003c/h2\u003e\n\u003cp\u003e需要进行更改的文件为\u003ccode\u003elayouts/partials/post_meta.html\u003c/code\u003e、\u003ccode\u003elayouts/partials/author.html\u003c/code\u003e、\u003ccode\u003elayouts/partials/extend_head.html\u003c/code\u003e以及\u003ccode\u003eparams\u003c/code\u003e。\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003elayouts/partials/post_meta.html\u003c/code\u003e的更改链接为\u003ccode\u003ehttps://github.com/xyming108/sulv-hugo-papermod/blob/main/layouts/partials/post_meta.html\u003c/code\u003e，其更改结果如下：\u003c/p\u003e","title":"博客模板"},{"content":"","permalink":"https://ajkpix.github.io/posts/read/read/","summary":"","title":"Text-to-Text Transfer Transformer(T5)"},{"content":"关于我\n性别: 男 职业: 研究僧 运动: 跑步、乒乓球、爬山 ","permalink":"https://ajkpix.github.io/about/","summary":"\u003cp style=\"font-size: 25px;\"\u003e关于我\u003c/p\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e性别:\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e男\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e职业:\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e研究僧\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e运动:\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e跑步、乒乓球、爬山\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"🙋🏻‍♂️关于"},{"content":"","permalink":"https://ajkpix.github.io/posts/blog/blog/","summary":"","title":"Blog"},{"content":"","permalink":"https://ajkpix.github.io/posts/life/life/","summary":"","title":"Life"},{"content":"\r👉友链格式\r名称： Sulv\u0026rsquo;s Blog 网址： https://www.sulvblog.cn 图标： https://www.sulvblog.cn/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求\r秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n👉Hugo博客交流群\r787018782\n","permalink":"https://ajkpix.github.io/links/","summary":"\u003cbr/\u003e\r\n\u003cbr/\u003e\r\n\u003cbr/\u003e\r\n\u003cbr/\u003e\r\n\u003cbr/\u003e\r\n\u003cdiv style=\"font-size: 20px;\" class=\"youlian\"\u003e👉友链格式\u003c/div\u003e\r\n\u003cdiv style=\"font-size: 16px;\"\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e名称：\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eSulv\u0026rsquo;s Blog\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e网址：\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://www.sulvblog.cn\"\u003ehttps://www.sulvblog.cn\u003c/a\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e图标：\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://www.sulvblog.cn/img/Q.gif\"\u003ehttps://www.sulvblog.cn/img/Q.gif\u003c/a\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e描述：\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e一个记录技术、阅读、生活的博客\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e\r\n\u003cbr/\u003e\r\n\u003cdiv style=\"font-size: 20px;\"\u003e👉友链申请要求\u003c/div\u003e\r\n\u003cblockquote\u003e\n\u003cp\u003e秉承互换友链原则、文章定期更新\u003c!-- 、网站在工信部备案 --\u003e、不能有太多广告、个人描述字数控制在15字内\u003c/p\u003e","title":"🤝友链"}]